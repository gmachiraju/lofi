{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook contains a portion of results from our NeurIPS 2023 submission. We attempt training on chunk and token embeddings and explore how these embeddings may carry explanatory signal for classification. The hypothesis is that we've encoded positional information sufficiently that we can now learn on the concatenated embeddings themselves.\n",
    "\n",
    "This notebook is specifically Step 1 in the process: gathering embeddings and creating chunk-embedded sequence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sequence-level Dataset Construction\n",
    "- Running inference with trained $f_\\theta$ to construct $\\mathbf{Z}$ embedded sequences, for both train and test\n",
    "- We also show a bit of the process before we dive into full-sequence training. We get an idea of what clustering over token embeddings looks like before the conversion to $\\mathbf{C}$ sequence mosaics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from embed_patches import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n",
      "GPU detected? True\n",
      "\n",
      "Note: gpu available & selected!\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "\n",
    "USE_GPU = True\n",
    "print(\"GPU detected?\", torch.cuda.is_available())\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "\tdevice = torch.device('cuda')\n",
    "\tprint(\"\\nNote: gpu available & selected!\")\n",
    "else:\n",
    "\tdevice = torch.device('cpu')\n",
    "\tprint(\"\\nNote: gpu NOT available!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1A. Get train set stats/info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering dimensions...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "patch_dir = \"/home/data/tinycam/train/train.hdf5\"\n",
    "label_dict_path = \"/home/lofi/lofi/src/outputs/train-cam-cam16-224-background-labeldict.obj\"\n",
    "image_names = print_X_names(label_dict_path)\n",
    "train_dim_dict = gather_Z_dims(patch_dir, image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max dims (gathered from extracted patches) are: 102 108\n"
     ]
    }
   ],
   "source": [
    "i_max = 0\n",
    "j_max = 0\n",
    "for v in train_dim_dict.values():\n",
    "    if v[0] > i_max:\n",
    "        i_max = v[0]\n",
    "    if v[1] > j_max:\n",
    "        j_max = v[1]\n",
    "\n",
    "print(\"max dims (gathered from extracted patches) are:\", i_max, j_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import deserialize\n",
    "custom_train_dict_path = \"/home/data/tinycam/test/cam16-eval/my_data/cam16_train_dim_dict.obj\"\n",
    "train_dims = deserialize(custom_train_dict_path)\n",
    "\n",
    "image_names = []\n",
    "train_dim_dict = {}\n",
    "for key in train_dims.keys():\n",
    "    im_id = key.split(\".tif\")[0]\n",
    "    image_names.append(im_id)\n",
    "    train_dim_dict[im_id] = (train_dims[key][3][1], train_dims[key][3][0]) # swap dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using original image dimensions, max sizes are: 123 123\n"
     ]
    }
   ],
   "source": [
    "i_max = 0\n",
    "j_max = 0\n",
    "for v in train_dim_dict.values():\n",
    "    if v[0] > i_max:\n",
    "        i_max = v[0]\n",
    "    if v[1] > j_max:\n",
    "        j_max = v[1]\n",
    "\n",
    "print(\"Using original image dimensions, max sizes are:\", i_max, j_max)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B. Get test set stats/info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>meta1</th>\n",
       "      <th>meta2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_001</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>IDC</td>\n",
       "      <td>Macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_002</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>ILC</td>\n",
       "      <td>Macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_003</td>\n",
       "      <td>Normal</td>\n",
       "      <td>DCIS</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_004</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>IDC</td>\n",
       "      <td>Micro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_005</td>\n",
       "      <td>Normal</td>\n",
       "      <td>DCIS</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   class meta1  meta2\n",
       "0  test_001   Tumor   IDC  Macro\n",
       "1  test_002   Tumor   ILC  Macro\n",
       "2  test_003  Normal  DCIS   None\n",
       "3  test_004   Tumor   IDC  Micro\n",
       "4  test_005  Normal  DCIS   None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ref_path = \"/home/data/tinycam/test/cam16-eval/csnaftp_gdrive-16/reference.csv\"\n",
    "ref_df = pd.read_csv(ref_path, header=None, names=[\"id\", \"class\", \"meta1\", \"meta2\"])\n",
    "ref_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = [1 if el==\"Tumor\" else 0 for el in ref_df[\"class\"]]\n",
    "test_label_dict = dict(zip(ref_df[\"id\"], test_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import deserialize\n",
    "custom_test_dict_path = \"/home/data/tinycam/test/cam16-eval/my_data/cam16_test_dim_dict.obj\"\n",
    "test_dims = deserialize(custom_test_dict_path)\n",
    "\n",
    "gt_path = \"/home/data/tinycam/test/cam16-eval/csnaftp_gdrive-16/lesion_annotations\"\n",
    "gt_files = os.listdir(gt_path)\n",
    "\n",
    "image_names = []\n",
    "test_dim_dict = {}\n",
    "for key in test_dims.keys():\n",
    "    im_id = key.split(\".tif\")[0]\n",
    "    image_names.append(im_id)\n",
    "    test_dim_dict[im_id] = (test_dims[key][3][1], test_dims[key][3][0]) # swap dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sizes are: 123 118\n"
     ]
    }
   ],
   "source": [
    "i_max = 0\n",
    "j_max = 0\n",
    "for v in test_dim_dict.values():\n",
    "    if v[0] > i_max:\n",
    "        i_max = v[0]\n",
    "    if v[1] > j_max:\n",
    "        j_max = v[1]\n",
    "\n",
    "print(\"max sizes are:\", i_max, j_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import serialize\n",
    "label_dict_path_test = \"/home/lofi/lofi/src/outputs/test-cam-cam16-224-background-labeldict.obj\"\n",
    "utils.serialize(test_label_dict, label_dict_path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note these values above:* we want to pad our images to all be the same size for any downstream learning. Say 124 x 124 for the padding."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1C. Generating Training Masks\n",
    "We don't need these for training, but will use for some statistics. The functions here simpply relate numpy coords with salient objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cam_process import computeEvaluationMaskXML_lowres\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"/home/data/tinycam/test/cam16-eval/gigadb-16-17/lesion_annotations (1)\"\n",
    "gt_save_path = \"/home/data/tinycam/train/gt_masks\"\n",
    "#-------rerun if needed: can take 15-20min-----------\n",
    "# level, resolution = 5, None\n",
    "# print(\"we have\", len(os.listdir(gt_path)), \"masks to generate!\")\n",
    "# for i, mask in enumerate(os.listdir(gt_path)):\n",
    "#     id = mask.split(\".xml\")[0]\n",
    "#     print(\"started processing mask\", i, \"| ID:\", id)\n",
    "#     og_dims = (train_dims[id + \".tif\"][0][1], train_dims[id + \".tif\"][0][0]) # swap dims\n",
    "#     # og_dims = test_dims[id + \".tif\"][0]\n",
    "#     mask_np = computeEvaluationMaskXML_lowres(gt_path + \"/\" + mask, og_dims, resolution, level)\n",
    "#     if mask_np is None:\n",
    "#         break\n",
    "#     np.save(gt_save_path + \"/\" + id + \"_gt\", mask_np)\n",
    "#     print(\"finished processing mask\", i, \"| ID:\", id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a lookup dictionary of salient objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- run again if you want, 2 min------\n",
    "# gt_dict = {}\n",
    "# gt_path = \"/home/data/tinycam/train/gt_masks/\"\n",
    "# for idx, gt_file in enumerate(os.listdir(gt_path)):\n",
    "#     gt_mask = np.load(gt_path + \"/\" + gt_file)\n",
    "#     gt_id = gt_file.split(\"_gt.npy\")[0] \n",
    "#     new_dims = train_dims[gt_id + \".tif\"][3]\n",
    "#     gt_mask_sm = cv2.resize(gt_mask, (new_dims[1], new_dims[0]), interpolation=cv2.INTER_AREA)\n",
    "#     to_add = dict(((j,i), int(gt_mask_sm[i][j])) for i in range(len(gt_mask_sm)) for j in range(len(gt_mask_sm[0])))\n",
    "#     gt_dict[gt_id] = to_add\n",
    "\n",
    "# utils.serialize(gt_dict, \"outputs/train_so_dict.obj\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D. Model Inference on Train Set\n",
    "Let's now load and set up model $f_\\theta$. Choices for Camelyon16 data include:\n",
    "- `\"tile2vec\"`: an unsupervised learning model, ResNetr-16 trained from scratch\n",
    "- `\"vit_iid\"`: a (weakly) supervised learning model, ViT trained from scratch on IID fuzzy targets\n",
    "- `\"clip\"`: a Foundation Model, specifically a Vision-Langauge Model (VLM), pre-trained and used out of the box\n",
    "- `\"plip\"`: a Foundation Model/VLM, pre-trained and used out of the box; clip-style model that is fine-tuned on Patholgy chunks\n",
    "- `None`: skip inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model you want to run for inference\n",
    "modelstr = \"vit_iid\" #\"tile2vec\", \"vit_iid\", \"clip\", \"plip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelstr == \"tile2vec\":\n",
    "    from models import ResNet18 \n",
    "    model = ResNet18(n_classes=2, in_channels=3, z_dim=128, supervised=False, no_relu=False, loss_type='triplet', tile_size=224, activation='relu')\n",
    "    chkpt = \"/home/lofi/lofi/models/cam/to-port/ResNet18-hdf5_triplets_random_loading-224-label_selfsup-custom_loss-on_cam-cam16-filtration_background.sd\"\n",
    "    checkpoint = torch.load(chkpt, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    prev_epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "elif modelstr == \"vit_iid\":\n",
    "    from vit_pytorch import ViT\n",
    "    model = ViT(image_size = 224, patch_size=16, num_classes=2, dim=1024, depth=6, heads=16, mlp_dim=2048, dropout=0.1, emb_dropout=0.1)\n",
    "    chkpt = \"/home/lofi/lofi/models/cam/ViT-hdf5_random_loading-224-label_inherit-bce_loss-on_cam-cam16-filtration_background.sd\"\n",
    "    checkpoint = torch.load(chkpt, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    prev_epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "elif modelstr == \"clip\":\n",
    "    from transformers import CLIPProcessor, CLIPTokenizer, CLIPModel\n",
    "    tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    model_clip = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "elif modelstr == \"plip\":\n",
    "    from transformers import AutoProcessor, AutoTokenizer, AutoModelForZeroShotImageClassification\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"vinid/plip\")\n",
    "    processor = AutoProcessor.from_pretrained(\"vinid/plip\")\n",
    "    model_plip = AutoModelForZeroShotImageClassification.from_pretrained(\"vinid/plip\")\n",
    "elif modelstr == None:\n",
    "    print(\"No model selected for inference! Skipping inference...\")\n",
    "else:\n",
    "    print(\"Not yet supported for inference! Skipping inference...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run inference on the training set. We want to process all patches in the training set and then attempt to learn from the concatenated embeddings\n",
    "\n",
    "*Note:* tile2vec should take roughly 20min with 1 T4 GPU, and then closer to 60-90min for plip/clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if modelstr == \"tile2vec\":\n",
    "#     patch_dir = \"/home/data/tinycam/train/train.hdf5\"\n",
    "#     save_dir = \"/home/data/tinycam/train/Zs\"\n",
    "#     construct_Zs_efficient(model, patch_dir, train_dim_dict, save_dir, device, scope=\"all\")\n",
    "# elif modelstr == \"vit_iid\":\n",
    "#     patch_dir = \"/home/data/tinycam/train/train.hdf5\"\n",
    "#     save_dir = \"/home/data/tinycam/train/Zs_vit\"\n",
    "#     construct_Zs_efficient(model, patch_dir, train_dim_dict, save_dir, device, scope=\"all\", modelstr=modelstr, embed_format=\"memmap\", overwrite_flag=True) # the embeddings are much alrger for vit\n",
    "# elif modelstr == \"clip\":\n",
    "#     patch_dir = \"/home/data/tinycam/train/train.hdf5\"\n",
    "#     save_dir = \"/home/data/tinycam/train/Zs_clip\"\n",
    "#     construct_Zs_efficient(model_clip, patch_dir, train_dim_dict, save_dir, device, scope=\"all\", modelstr=modelstr, processor=processor, tokenizer=tokenizer)\n",
    "# elif modelstr == \"plip\":\n",
    "#     patch_dir = \"/home/data/tinycam/train/train.hdf5\"\n",
    "#     save_dir = \"/home/data/tinycam/train/Zs_plip\"\n",
    "#     construct_Zs_efficient(model_plip, patch_dir, train_dim_dict, save_dir, device, scope=\"all\", modelstr=modelstr, processor=processor, tokenizer=tokenizer)\n",
    "# elif modelstr == None:\n",
    "#     print(\"No model selected for inference! Skipping inference...\")\n",
    "# else:\n",
    "#     print(\"Not yet supported for inference! Skipping inference...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1E. Model Inference on Test Set\n",
    "Expect 20-45min of GPU computation depending on model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have this # of test set images: 129\n",
      "We have 182109 unique patches to embed\n",
      "On sample number 0 of 129\n",
      "(40, 48)\n",
      "On ID: test_086\n",
      "padding C (41x49) with H,W crops at: [(41, 82), (37, 86)]\n",
      "On sample number 1 of 129\n",
      "(48, 48)\n",
      "On ID: test_122\n",
      "padding C (49x49) with H,W crops at: [(37, 86), (37, 86)]\n",
      "On sample number 2 of 129\n",
      "(58, 54)\n",
      "On ID: test_004\n",
      "padding C (59x55) with H,W crops at: [(32, 91), (34, 89)]\n",
      "On sample number 3 of 129\n",
      "(121, 54)\n",
      "On ID: test_054\n",
      "padding C (122x55) with H,W crops at: [(1, 123), (34, 89)]\n",
      "On sample number 4 of 129\n",
      "(123, 54)\n",
      "On ID: test_067\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 5 of 129\n",
      "(36, 75)\n",
      "On ID: test_089\n",
      "padding C (37x76) with H,W crops at: [(43, 80), (24, 100)]\n",
      "On sample number 6 of 129\n",
      "(111, 55)\n",
      "On ID: test_081\n",
      "padding C (112x56) with H,W crops at: [(6, 118), (34, 90)]\n",
      "On sample number 7 of 129\n",
      "(118, 54)\n",
      "On ID: test_074\n",
      "padding C (119x55) with H,W crops at: [(2, 121), (34, 89)]\n",
      "On sample number 8 of 129\n",
      "(56, 109)\n",
      "On ID: test_127\n",
      "padding C (57x110) with H,W crops at: [(33, 90), (7, 117)]\n",
      "On sample number 9 of 129\n",
      "(50, 34)\n",
      "On ID: test_046\n",
      "padding C (51x35) with H,W crops at: [(36, 87), (44, 79)]\n",
      "On sample number 10 of 129\n",
      "(54, 68)\n",
      "On ID: test_080\n",
      "padding C (55x69) with H,W crops at: [(34, 89), (27, 96)]\n",
      "On sample number 11 of 129\n",
      "(46, 52)\n",
      "On ID: test_094\n",
      "padding C (47x53) with H,W crops at: [(38, 85), (35, 88)]\n",
      "On sample number 12 of 129\n",
      "(123, 54)\n",
      "On ID: test_021\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 13 of 129\n",
      "(114, 54)\n",
      "On ID: test_103\n",
      "padding C (115x55) with H,W crops at: [(4, 119), (34, 89)]\n",
      "On sample number 14 of 129\n",
      "(119, 54)\n",
      "On ID: test_050\n",
      "padding C (120x55) with H,W crops at: [(2, 122), (34, 89)]\n",
      "On sample number 15 of 129\n",
      "(111, 55)\n",
      "On ID: test_011\n",
      "padding C (112x56) with H,W crops at: [(6, 118), (34, 90)]\n",
      "On sample number 16 of 129\n",
      "(123, 54)\n",
      "On ID: test_029\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 17 of 129\n",
      "(119, 54)\n",
      "On ID: test_112\n",
      "padding C (120x55) with H,W crops at: [(2, 122), (34, 89)]\n",
      "On sample number 18 of 129\n",
      "(60, 73)\n",
      "On ID: test_113\n",
      "padding C (61x74) with H,W crops at: [(31, 92), (25, 99)]\n",
      "On sample number 19 of 129\n",
      "(123, 54)\n",
      "On ID: test_083\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 20 of 129\n",
      "(52, 91)\n",
      "On ID: test_120\n",
      "padding C (53x92) with H,W crops at: [(35, 88), (16, 108)]\n",
      "On sample number 21 of 129\n",
      "(118, 54)\n",
      "On ID: test_117\n",
      "padding C (119x55) with H,W crops at: [(2, 121), (34, 89)]\n",
      "On sample number 22 of 129\n",
      "(20, 52)\n",
      "On ID: test_055\n",
      "padding C (21x53) with H,W crops at: [(51, 72), (35, 88)]\n",
      "On sample number 23 of 129\n",
      "(46, 66)\n",
      "On ID: test_084\n",
      "padding C (47x67) with H,W crops at: [(38, 85), (28, 95)]\n",
      "On sample number 24 of 129\n",
      "(123, 54)\n",
      "On ID: test_023\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 25 of 129\n",
      "(56, 61)\n",
      "On ID: test_014\n",
      "padding C (57x62) with H,W crops at: [(33, 90), (31, 93)]\n",
      "On sample number 26 of 129\n",
      "(123, 54)\n",
      "On ID: test_024\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 27 of 129\n",
      "(118, 54)\n",
      "On ID: test_051\n",
      "padding C (119x55) with H,W crops at: [(2, 121), (34, 89)]\n",
      "On sample number 28 of 129\n",
      "(50, 48)\n",
      "On ID: test_001\n",
      "padding C (51x49) with H,W crops at: [(36, 87), (37, 86)]\n",
      "On sample number 29 of 129\n",
      "(52, 86)\n",
      "On ID: test_034\n",
      "padding C (53x87) with H,W crops at: [(35, 88), (18, 105)]\n",
      "On sample number 30 of 129\n",
      "(123, 54)\n",
      "On ID: test_087\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 31 of 129\n",
      "(121, 54)\n",
      "On ID: test_130\n",
      "padding C (122x55) with H,W crops at: [(1, 123), (34, 89)]\n",
      "On sample number 32 of 129\n",
      "(123, 54)\n",
      "On ID: test_070\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 33 of 129\n",
      "(50, 57)\n",
      "On ID: test_110\n",
      "padding C (51x58) with H,W crops at: [(36, 87), (33, 91)]\n",
      "On sample number 34 of 129\n",
      "(111, 55)\n",
      "On ID: test_119\n",
      "padding C (112x56) with H,W crops at: [(6, 118), (34, 90)]\n",
      "On sample number 35 of 129\n",
      "(58, 48)\n",
      "On ID: test_031\n",
      "padding C (59x49) with H,W crops at: [(32, 91), (37, 86)]\n",
      "On sample number 36 of 129\n",
      "(123, 54)\n",
      "On ID: test_017\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 37 of 129\n",
      "(32, 93)\n",
      "On ID: test_109\n",
      "padding C (33x94) with H,W crops at: [(45, 78), (15, 109)]\n",
      "On sample number 38 of 129\n",
      "(52, 70)\n",
      "On ID: test_105\n",
      "padding C (53x71) with H,W crops at: [(35, 88), (26, 97)]\n",
      "On sample number 39 of 129\n",
      "(121, 54)\n",
      "On ID: test_006\n",
      "padding C (122x55) with H,W crops at: [(1, 123), (34, 89)]\n",
      "On sample number 40 of 129\n",
      "(54, 61)\n",
      "On ID: test_114\n",
      "padding C (55x62) with H,W crops at: [(34, 89), (31, 93)]\n",
      "On sample number 41 of 129\n",
      "(62, 68)\n",
      "On ID: test_037\n",
      "padding C (63x69) with H,W crops at: [(30, 93), (27, 96)]\n",
      "On sample number 42 of 129\n",
      "(42, 70)\n",
      "On ID: test_077\n",
      "padding C (43x71) with H,W crops at: [(40, 83), (26, 97)]\n",
      "On sample number 43 of 129\n",
      "(123, 54)\n",
      "On ID: test_035\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 44 of 129\n",
      "(48, 54)\n",
      "On ID: test_099\n",
      "padding C (49x55) with H,W crops at: [(37, 86), (34, 89)]\n",
      "On sample number 45 of 129\n",
      "(123, 54)\n",
      "On ID: test_093\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 46 of 129\n",
      "(123, 54)\n",
      "On ID: test_002\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 47 of 129\n",
      "(121, 54)\n",
      "On ID: test_076\n",
      "padding C (122x55) with H,W crops at: [(1, 123), (34, 89)]\n",
      "On sample number 48 of 129\n",
      "(54, 86)\n",
      "On ID: test_071\n",
      "padding C (55x87) with H,W crops at: [(34, 89), (18, 105)]\n",
      "On sample number 49 of 129\n",
      "(30, 43)\n",
      "On ID: test_065\n",
      "padding C (31x44) with H,W crops at: [(46, 77), (40, 84)]\n",
      "On sample number 50 of 129\n",
      "(123, 53)\n",
      "On ID: test_124\n",
      "padding C (124x54) with H,W crops at: [(0, 124), (35, 89)]\n",
      "On sample number 51 of 129\n",
      "(121, 54)\n",
      "On ID: test_059\n",
      "padding C (122x55) with H,W crops at: [(1, 123), (34, 89)]\n",
      "On sample number 52 of 129\n",
      "(48, 86)\n",
      "On ID: test_066\n",
      "padding C (49x87) with H,W crops at: [(37, 86), (18, 105)]\n",
      "On sample number 53 of 129\n",
      "(117, 54)\n",
      "On ID: test_104\n",
      "padding C (118x55) with H,W crops at: [(3, 121), (34, 89)]\n",
      "On sample number 54 of 129\n",
      "(48, 45)\n",
      "On ID: test_047\n",
      "padding C (49x46) with H,W crops at: [(37, 86), (39, 85)]\n",
      "On sample number 55 of 129\n",
      "(56, 52)\n",
      "On ID: test_058\n",
      "padding C (57x53) with H,W crops at: [(33, 90), (35, 88)]\n",
      "On sample number 56 of 129\n",
      "(123, 54)\n",
      "On ID: test_115\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 57 of 129\n",
      "(32, 98)\n",
      "On ID: test_101\n",
      "padding C (33x99) with H,W crops at: [(45, 78), (12, 111)]\n",
      "On sample number 58 of 129\n",
      "(106, 54)\n",
      "On ID: test_097\n",
      "padding C (107x55) with H,W crops at: [(8, 115), (34, 89)]\n",
      "On sample number 59 of 129\n",
      "(58, 57)\n",
      "On ID: test_041\n",
      "padding C (59x58) with H,W crops at: [(32, 91), (33, 91)]\n",
      "On sample number 60 of 129\n",
      "(118, 54)\n",
      "On ID: test_064\n",
      "padding C (119x55) with H,W crops at: [(2, 121), (34, 89)]\n",
      "On sample number 61 of 129\n",
      "(123, 51)\n",
      "On ID: test_060\n",
      "padding C (124x52) with H,W crops at: [(0, 124), (36, 88)]\n",
      "On sample number 62 of 129\n",
      "(123, 54)\n",
      "On ID: test_032\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 63 of 129\n",
      "(123, 54)\n",
      "On ID: test_123\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 64 of 129\n",
      "(122, 54)\n",
      "On ID: test_106\n",
      "padding C (123x55) with H,W crops at: [(0, 123), (34, 89)]\n",
      "On sample number 65 of 129\n",
      "(42, 45)\n",
      "On ID: test_018\n",
      "padding C (43x46) with H,W crops at: [(40, 83), (39, 85)]\n",
      "On sample number 66 of 129\n",
      "(118, 54)\n",
      "On ID: test_072\n",
      "padding C (119x55) with H,W crops at: [(2, 121), (34, 89)]\n",
      "On sample number 67 of 129\n",
      "(54, 61)\n",
      "On ID: test_078\n",
      "padding C (55x62) with H,W crops at: [(34, 89), (31, 93)]\n",
      "On sample number 68 of 129\n",
      "(123, 54)\n",
      "On ID: test_040\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 69 of 129\n",
      "(120, 54)\n",
      "On ID: test_100\n",
      "padding C (121x55) with H,W crops at: [(1, 122), (34, 89)]\n",
      "On sample number 70 of 129\n",
      "(121, 54)\n",
      "On ID: test_082\n",
      "padding C (122x55) with H,W crops at: [(1, 123), (34, 89)]\n",
      "On sample number 71 of 129\n",
      "(42, 73)\n",
      "On ID: test_022\n",
      "padding C (43x74) with H,W crops at: [(40, 83), (25, 99)]\n",
      "On sample number 72 of 129\n",
      "(123, 54)\n",
      "On ID: test_056\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 73 of 129\n",
      "(123, 54)\n",
      "On ID: test_107\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 74 of 129\n",
      "(123, 54)\n",
      "On ID: test_126\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 75 of 129\n",
      "(123, 54)\n",
      "On ID: test_003\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 76 of 129\n",
      "(123, 54)\n",
      "On ID: test_068\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 77 of 129\n",
      "(123, 54)\n",
      "On ID: test_085\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 78 of 129\n",
      "(121, 54)\n",
      "On ID: test_118\n",
      "padding C (122x55) with H,W crops at: [(1, 123), (34, 89)]\n",
      "On sample number 79 of 129\n",
      "(123, 54)\n",
      "On ID: test_091\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 80 of 129\n",
      "(16, 75)\n",
      "On ID: test_062\n",
      "padding C (17x76) with H,W crops at: [(53, 70), (24, 100)]\n",
      "On sample number 81 of 129\n",
      "(48, 57)\n",
      "On ID: test_079\n",
      "padding C (49x58) with H,W crops at: [(37, 86), (33, 91)]\n",
      "On sample number 82 of 129\n",
      "(123, 54)\n",
      "On ID: test_027\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 83 of 129\n",
      "(122, 54)\n",
      "On ID: test_038\n",
      "padding C (123x55) with H,W crops at: [(0, 123), (34, 89)]\n",
      "On sample number 84 of 129\n",
      "(122, 54)\n",
      "On ID: test_096\n",
      "padding C (123x55) with H,W crops at: [(0, 123), (34, 89)]\n",
      "On sample number 85 of 129\n",
      "(52, 61)\n",
      "On ID: test_016\n",
      "padding C (53x62) with H,W crops at: [(35, 88), (31, 93)]\n",
      "On sample number 86 of 129\n",
      "(123, 54)\n",
      "On ID: test_015\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 87 of 129\n",
      "(52, 59)\n",
      "On ID: test_008\n",
      "padding C (53x60) with H,W crops at: [(35, 88), (32, 92)]\n",
      "On sample number 88 of 129\n",
      "(46, 54)\n",
      "On ID: test_048\n",
      "padding C (47x55) with H,W crops at: [(38, 85), (34, 89)]\n",
      "On sample number 89 of 129\n",
      "(123, 54)\n",
      "On ID: test_007\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 90 of 129\n",
      "(123, 54)\n",
      "On ID: test_043\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 91 of 129\n",
      "(122, 54)\n",
      "On ID: test_053\n",
      "padding C (123x55) with H,W crops at: [(0, 123), (34, 89)]\n",
      "On sample number 92 of 129\n",
      "(123, 54)\n",
      "On ID: test_108\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 93 of 129\n",
      "(54, 102)\n",
      "On ID: test_019\n",
      "padding C (55x103) with H,W crops at: [(34, 89), (10, 113)]\n",
      "On sample number 94 of 129\n",
      "(39, 48)\n",
      "On ID: test_116\n",
      "padding C (40x49) with H,W crops at: [(42, 82), (37, 86)]\n",
      "On sample number 95 of 129\n",
      "(123, 54)\n",
      "On ID: test_121\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 96 of 129\n",
      "(32, 61)\n",
      "On ID: test_095\n",
      "padding C (33x62) with H,W crops at: [(45, 78), (31, 93)]\n",
      "On sample number 97 of 129\n",
      "(123, 54)\n",
      "On ID: test_111\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 98 of 129\n",
      "(44, 57)\n",
      "On ID: test_063\n",
      "padding C (45x58) with H,W crops at: [(39, 84), (33, 91)]\n",
      "On sample number 99 of 129\n",
      "(123, 54)\n",
      "On ID: test_088\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 100 of 129\n",
      "(52, 73)\n",
      "On ID: test_098\n",
      "padding C (53x74) with H,W crops at: [(35, 88), (25, 99)]\n",
      "On sample number 101 of 129\n",
      "(123, 54)\n",
      "On ID: test_057\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 102 of 129\n",
      "(58, 70)\n",
      "On ID: test_092\n",
      "padding C (59x71) with H,W crops at: [(32, 91), (26, 97)]\n",
      "On sample number 103 of 129\n",
      "(122, 54)\n",
      "On ID: test_052\n",
      "padding C (123x55) with H,W crops at: [(0, 123), (34, 89)]\n",
      "On sample number 104 of 129\n",
      "(52, 59)\n",
      "On ID: test_125\n",
      "padding C (53x60) with H,W crops at: [(35, 88), (32, 92)]\n",
      "On sample number 105 of 129\n",
      "(123, 54)\n",
      "On ID: test_013\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 106 of 129\n",
      "(123, 54)\n",
      "On ID: test_030\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 107 of 129\n",
      "(119, 54)\n",
      "On ID: test_129\n",
      "padding C (120x55) with H,W crops at: [(2, 122), (34, 89)]\n",
      "On sample number 108 of 129\n",
      "(123, 54)\n",
      "On ID: test_036\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 109 of 129\n",
      "(58, 105)\n",
      "On ID: test_033\n",
      "padding C (59x106) with H,W crops at: [(32, 91), (9, 115)]\n",
      "On sample number 110 of 129\n",
      "(115, 48)\n",
      "On ID: test_010\n",
      "padding C (116x49) with H,W crops at: [(4, 120), (37, 86)]\n",
      "On sample number 111 of 129\n",
      "(44, 86)\n",
      "On ID: test_028\n",
      "padding C (45x87) with H,W crops at: [(39, 84), (18, 105)]\n",
      "On sample number 112 of 129\n",
      "(119, 54)\n",
      "On ID: test_090\n",
      "padding C (120x55) with H,W crops at: [(2, 122), (34, 89)]\n",
      "On sample number 113 of 129\n",
      "(58, 118)\n",
      "On ID: test_069\n",
      "padding C (59x119) with H,W crops at: [(32, 91), (2, 121)]\n",
      "On sample number 114 of 129\n",
      "(118, 54)\n",
      "On ID: test_075\n",
      "padding C (119x55) with H,W crops at: [(2, 121), (34, 89)]\n",
      "On sample number 115 of 129\n",
      "(123, 54)\n",
      "On ID: test_039\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 116 of 129\n",
      "(120, 54)\n",
      "On ID: test_009\n",
      "padding C (121x55) with H,W crops at: [(1, 122), (34, 89)]\n",
      "On sample number 117 of 129\n",
      "(123, 54)\n",
      "On ID: test_020\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 118 of 129\n",
      "(120, 54)\n",
      "On ID: test_061\n",
      "padding C (121x55) with H,W crops at: [(1, 122), (34, 89)]\n",
      "On sample number 119 of 129\n",
      "(48, 89)\n",
      "On ID: test_073\n",
      "padding C (49x90) with H,W crops at: [(37, 86), (17, 107)]\n",
      "On sample number 120 of 129\n",
      "(62, 107)\n",
      "On ID: test_102\n",
      "padding C (63x108) with H,W crops at: [(30, 93), (8, 116)]\n",
      "On sample number 121 of 129\n",
      "(58, 54)\n",
      "On ID: test_026\n",
      "padding C (59x55) with H,W crops at: [(32, 91), (34, 89)]\n",
      "On sample number 122 of 129\n",
      "(123, 54)\n",
      "On ID: test_045\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 123 of 129\n",
      "(44, 70)\n",
      "On ID: test_012\n",
      "padding C (45x71) with H,W crops at: [(39, 84), (26, 97)]\n",
      "On sample number 124 of 129\n",
      "(38, 29)\n",
      "On ID: test_128\n",
      "padding C (39x30) with H,W crops at: [(42, 81), (47, 77)]\n",
      "On sample number 125 of 129\n",
      "(42, 50)\n",
      "On ID: test_044\n",
      "padding C (43x51) with H,W crops at: [(40, 83), (36, 87)]\n",
      "On sample number 126 of 129\n",
      "(123, 54)\n",
      "On ID: test_025\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "On sample number 127 of 129\n",
      "(60, 75)\n",
      "On ID: test_042\n",
      "padding C (61x76) with H,W crops at: [(31, 92), (24, 100)]\n",
      "On sample number 128 of 129\n",
      "(123, 54)\n",
      "On ID: test_005\n",
      "padding C (124x55) with H,W crops at: [(0, 124), (34, 89)]\n",
      "serialized sampled numpy embeds at: test_vit_iid_sampled_inference_z_embeds.obj\n",
      "saved Z tensors at: /home/data/tinycam/test/Zs_vit\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# if modelstr == \"tile2vec\":\n",
    "#     patch_dir = \"/home/data/tinycam/test/test.hdf5\"\n",
    "#     save_dir = \"/home/data/tinycam/test/Zs\"\n",
    "#     construct_Zs_efficient(model, patch_dir, test_dim_dict, save_dir, device, scope=\"all\", arm=\"test\")\n",
    "# elif modelstr == \"vit_iid\":\n",
    "#     patch_dir = \"/home/data/tinycam/test/test.hdf5\"\n",
    "#     save_dir = \"/home/data/tinycam/test/Zs_vit\"\n",
    "#     construct_Zs_efficient(model, patch_dir, test_dim_dict, save_dir, device, scope=\"all\", modelstr=\"vit_iid\", arm=\"test\")\n",
    "# elif modelstr == \"clip\":\n",
    "#     patch_dir = \"/home/data/tinycam/test/test.hdf5\"\n",
    "#     save_dir = \"/home/data/tinycam/test/Zs_clip\" \n",
    "#     construct_Zs_efficient(model_clip, patch_dir, test_dim_dict, save_dir, device, scope=\"all\", modelstr=\"clip\", processor=processor, tokenizer=tokenizer, arm=\"test\")\n",
    "# elif modelstr == \"plip\":\n",
    "#     patch_dir = \"/home/data/tinycam/test/test.hdf5\"\n",
    "#     save_dir = \"/home/data/tinycam/test/Zs_plip\"\n",
    "#     construct_Zs_efficient(model_plip, patch_dir, test_dim_dict, save_dir, device, scope=\"all\", modelstr=\"plip\", processor=processor, tokenizer=tokenizer, arm=\"test\")\n",
    "# elif modelstr == None:\n",
    "#     print(\"No model selected for inference! Skipping inference...\")\n",
    "# else:\n",
    "#     print(\"Not yet supported for inference! Skipping inference...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now inference is complete, we can then take a look at the data sprites in `Cam-Step2-Viz.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
